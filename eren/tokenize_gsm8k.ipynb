{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e8de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"openai/gsm8k\", \"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65770d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc466f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-4b-pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbea7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tool_call_pattern = re.compile(r'(<<[^>]+>>)([^<]*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a1bfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(20, 69), match='<<48/2=24>>24 clips in May.\\nNatalia sold 48+24 =>,\n",
       " <re.Match object; span=(69, 126), match='<<48+24=72>>72 clips altogether in April and May.>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tool_call_pattern.finditer(ds['train'][0]['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55a6ba32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<add>(30, 46, 18)=100'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_tool_call(\"30+46+18=100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e88ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tool_call(expression: str):\n",
    "    \"\"\"\n",
    "    Parses a mathematical expression and converts it into the ToolkenGPT format.\n",
    "    Examples: \n",
    "    \"48/2=24\" -> \"<divide>(48, 2)=24\"\n",
    "    \"+30+46+38+11+18=143\" -> \"<add>(30, 46, 38, 11, 18)=143\"\n",
    "    \"\"\"\n",
    "    # Simple mapping from operator to function name\n",
    "    op_to_func = {\n",
    "        '+': 'add',\n",
    "        '-': 'subtract',\n",
    "        '*': 'multiply',\n",
    "        '/': 'divide'\n",
    "    }\n",
    "\n",
    "    # Find the operator and split on equals sign\n",
    "    if '=' in expression:\n",
    "        expr_part, result = expression.split('=', 1)\n",
    "        result = result.strip()\n",
    "        \n",
    "        # Handle multiple additions/subtractions\n",
    "        for op, func_name in op_to_func.items():\n",
    "            if op in expr_part:\n",
    "                # Skip if it's just a leading sign\n",
    "                if expr_part.strip() == op:\n",
    "                    continue\n",
    "                    \n",
    "                # Split on operator, filter out empty strings\n",
    "                parts = [p.strip() for p in expr_part.split(op) if p.strip()]\n",
    "                \n",
    "                # If we found valid parts, convert to function call format\n",
    "                if parts:\n",
    "                    return f\"<{func_name}>({', '.join(parts)})={result}\"\n",
    "    \n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "111d3791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There were 9-4 = <<9-4=5>>5 other pills\\nEach of the other pills cost 1.50+5.50 = <<1.50+5.50=7>>7 dollars each.\\nThe 5 pills cost a total of 7*5 = <<7*5=35>>35 dollars.\\nThe first 4 pills cost 1.50*4 = <<1.50*4=6>>6 dollars in total.\\nHenry spent a total of 35+6 = <<35+6=41>>41 dollars.\\n#### 41'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][108]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9bafc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "# Get the index by searching through processed samples\n",
    "found_idx = next((i for i, sample in enumerate(processed_samples) \n",
    "                  if sample['text'] == original[108]['text']), None)\n",
    "print(found_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec2436c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First find how many kids from Riverside High are rejected: 20% * 120 kids = <<20*.01*120=24>>24 kids\\nThen find how many kids from West Side High are rejected: 70% * 90 kids = <<70*.01*90=63>>63 kids\\nThen find how many kids from Mountaintop High are rejected: 50 kids / 2 = <<50/2=25>>25 kids\\nThen add the number of kids from each school to find the total number of kids: 120 kids + 90 kids + 50 kids = <<120+90+50=260>>260 kids\\nThen subtract all the kids who were rejected from the total number of kids to find the number who got in: 260 kids - 24 kids - 63 kids - 25 kids = <<260-24-63-25=148>>148 kids\\n#### 148'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][140][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0523de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Fern is checking IDs to get into an R-rated movie. She denied 20% of the 120 kids from Riverside High, 70% of the 90 kids from West Side High, and half the 50 kids from Mountaintop High. How many kids got into the movie? Let's think step by step. First find how many kids from Riverside High are rejected: 20% * 120 kids = 24 kids\\nThen find how many kids from West Side High are rejected: 70% * 90 kids = 63 kids\\nThen find how many kids from Mountaintop High are rejected: 50 kids / 2 = 25 kids\\nThen add the number of kids from each school to find the total number of kids: 120 kids + 90 kids + 50 kids = 260 kids\\nThen subtract all the kids who were rejected from the total number of kids to find the number who got in: 260 kids - 24 kids - 63 kids - 25 kids = 148 kids\\n#### 148\",\n",
       " 'start_token_idx': [109, 139, 168, 212, 268],\n",
       " 'end_token_idx': [111, 141, 170, 215, 271],\n",
       " 'tar_eq': ['<multiply>(20, 0.01, 120)=24<eoe>',\n",
       "  '<multiply>(70, 0.01, 90)=63<eoe>',\n",
       "  '<divide>(50, 2)=25<eoe>',\n",
       "  '<add>(120, 90, 50)=260<eoe>',\n",
       "  '<subtract>(260, 24, 63, 25)=148<eoe>'],\n",
       " 'tar_number': ['24', '63', '25', '260', '148']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original[108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0586b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7473 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7473/7473 [00:15<00:00, 488.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch ratio: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "verbose = 1\n",
    "mismatches = 0\n",
    "\n",
    "\n",
    "processed_samples = []\n",
    "\n",
    "\n",
    "for sample in tqdm(ds['train']):\n",
    "    start_indices = []\n",
    "    end_indices = []\n",
    "    target_equations = []\n",
    "    target_numbers = []\n",
    "        \n",
    "    removed_chars_offset = 0\n",
    "\n",
    "    full_text = sample['question'] + \" Let's think step by step. \" + sample['answer']\n",
    "\n",
    "    matches = list(tool_call_pattern.finditer(full_text))\n",
    "\n",
    "    # Create the final clean text by removing only the <<...>> syntax.\n",
    "    clean_text = re.sub(r'<<[^>]+>>', '', full_text)\n",
    "\n",
    "    start_indices = []\n",
    "    end_indices = []\n",
    "    target_equations = []\n",
    "    target_numbers = []\n",
    "\n",
    "    removed_chars_offset = 0\n",
    "\n",
    "    for match in matches:\n",
    "        expression_part = match.group(1) # The <<...>> part\n",
    "    \n",
    "        expression = expression_part[2:-2] # The content inside\n",
    "        expression = re.sub(r'(?<=[\\s=+\\-*/])\\.(\\d+)', r'0.\\1', expression)  # Add 0 before decimal points\n",
    "\n",
    "        following_text = match.group(2) # The text after <<...>>\n",
    "        \n",
    "        # The pattern should handle negative numbers as well.\n",
    "        number_pattern = re.compile(r'-?[\\d,]*\\.?\\d+')\n",
    "        num_match = number_pattern.search(following_text)\n",
    "        num = num_match.group(0) if num_match else None\n",
    "        expected_num_str = expression.split('=')[-1].strip()\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            assert num == expected_num_str\n",
    "        except AssertionError:\n",
    "            mismatches += 1\n",
    "            print(\"-\"*25)\n",
    "            print(num_match)\n",
    "            print(f\"Full text: {sample['answer']}\")\n",
    "            print(\"/\"*10)\n",
    "            print(f\"Found match: {match.group(0)}\")\n",
    "            print(f\"Expression part: {expression_part}\")\n",
    "            print(f\"Following text: {following_text}\")\n",
    "            print(f\"Number found: {num}\")\n",
    "            print(f\"Expected number from expression: {expected_num_str}\")\n",
    "        \"\"\"\n",
    "        # 1. Calculate the character position of where the number *starts* in the clean_text.\n",
    "        char_pos_start = (match.start() - removed_chars_offset) + num_match.start()\n",
    "\n",
    "        # 2. Tokenize the clean text *before* the number's position to find the start_idx.\n",
    "        text_before_result = clean_text[:char_pos_start]\n",
    "        tokens_before = tokenizer.encode(text_before_result)\n",
    "        start_idx = len(tokens_before)\n",
    "\n",
    "        # 3. Calculate the character position of where the number *ends* in the clean_text.\n",
    "        char_pos_end = char_pos_start + len(num)\n",
    "        \n",
    "        # 4. Tokenize the clean text up to the *end* of the number. The length of this\n",
    "        #    token sequence is our end_idx.\n",
    "        text_up_to_end_of_result = clean_text[:char_pos_end]\n",
    "        tokens_up_to_end = tokenizer.encode(text_up_to_end_of_result)\n",
    "        end_idx = len(tokens_up_to_end)\n",
    "\n",
    "        # 5. Store the start and end indices for the current match.\n",
    "        start_indices.append(start_idx)\n",
    "        end_indices.append(end_idx)\n",
    "        target_equations.append(parse_tool_call(expression))\n",
    "\n",
    "        target_numbers.append(num)\n",
    "\n",
    "        # Update the offset for the next iteration by adding the length of the\n",
    "        # <<...>> syntax string we just processed.\n",
    "        removed_chars_offset += len(expression_part)\n",
    "\n",
    "        if num != expected_num_str and False:\n",
    "            print(f\"Text: {clean_text}\")\n",
    "            print(f\"Before: {text_before_result}\")\n",
    "            print(f\"After: {text_up_to_end_of_result}\")\n",
    "            print(f\"Target equations: {target_equations}\")\n",
    "    \n",
    "    processed_samples.append({\n",
    "            \"text\": clean_text,\n",
    "            \"start_token_idx\": start_indices,\n",
    "            \"end_token_idx\": end_indices,\n",
    "            \"tar_eq\": target_equations,\n",
    "            \"tar_number\": target_numbers,\n",
    "        })\n",
    "\n",
    "print(f\"Mismatch ratio: {mismatches/len(ds['train'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3b5771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<48+24=72>>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expression_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5a8c28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'48+24=72'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31f41502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'72 clips altogether in April and May.\\n#### 72'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "following_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f111fc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'72'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2862e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24f66b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23694"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mismatches_after_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dff6cbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict — total: 23716, matches (with correction): 23695, mismatches: 21\n",
      "--------------------------------------------------\n",
      "{'sample_idx': 929, 'tool_call_idx': 1, 's': 90, 't': 92, 'expected': '.25', 'span_text': '25'}\n",
      "L: 0/2= $.\n",
      "R:  on the half-priced\n",
      "--------------------------------------------------\n",
      "{'sample_idx': 1273, 'tool_call_idx': 0, 's': 66, 't': 69, 'expected': '.75', 'span_text': '$.75'}\n",
      "L: .5/2=\n",
      "R:  per pack\n",
      "So he\n",
      "--------------------------------------------------\n",
      "{'sample_idx': 1875, 'tool_call_idx': 0, 's': 75, 't': 77, 'expected': '.25', 'span_text': '25'}\n",
      "L: 5/60=.\n",
      "R:  hour head start\n",
      "That\n",
      "--------------------------------------------------\n",
      "{'sample_idx': 1957, 'tool_call_idx': 3, 's': 122, 't': 124, 'expected': '.5', 'span_text': '$.5'}\n",
      "L: -1.5=\n",
      "R: \n",
      "So he spent \n",
      "--------------------------------------------------\n",
      "{'sample_idx': 2270, 'tool_call_idx': 5, 's': 215, 't': 216, 'expected': '.8', 'span_text': '8'}\n",
      "L: 2/15=.\n",
      "R: \n",
      "#### 80\n",
      "--------------------------------------------------\n",
      "{'sample_idx': 2680, 'tool_call_idx': 0, 's': 80, 't': 81, 'expected': '.5', 'span_text': '5'}\n",
      "L: 6/12=.\n",
      "R:  years\n",
      "So it took\n",
      "--------------------------------------------------\n",
      "{'sample_idx': 2824, 'tool_call_idx': 1, 's': 93, 't': 95, 'expected': '.5', 'span_text': '$.5'}\n",
      "L: -1.5=\n",
      "R: \n",
      "So they made a\n",
      "--------------------------------------------------\n",
      "{'sample_idx': 3075, 'tool_call_idx': 0, 's': 76, 't': 78, 'expected': '.5', 'span_text': '$.5'}\n",
      "L: .5-1=\n",
      "R:  from each candy bar\n",
      "\n",
      "--------------------------------------------------\n",
      "{'sample_idx': 3422, 'tool_call_idx': 0, 's': 71, 't': 72, 'expected': '.1', 'span_text': '1'}\n",
      "L: /100=.\n",
      "R:  minute per piece\n",
      "So\n",
      "--------------------------------------------------\n",
      "{'sample_idx': 3506, 'tool_call_idx': 0, 's': 59, 't': 62, 'expected': '.56', 'span_text': '$.56'}\n",
      "L: -$.44=\n",
      "R:  in change.\n",
      "She\n"
     ]
    }
   ],
   "source": [
    "# Strict validation: update samples in-place with corrected indices and match status.\n",
    "strict_total = 0\n",
    "strict_ok = 0\n",
    "mismatches_after_correction = []\n",
    "\n",
    "for i, samp in enumerate(processed_samples):\n",
    "    # Initialize a new list to store the match status for each tool call in the sample\n",
    "    samp[\"strict_match\"] = []\n",
    "    \n",
    "    # keep tokenizer behavior consistent with above preprocessing (same encode)\n",
    "    token_ids = tokenizer.encode(samp[\"text\"])\n",
    "    \n",
    "    # Enumerate to get the index 'j' for updating the lists\n",
    "    for j, (s, t, num) in enumerate(zip(samp[\"start_token_idx\"], samp[\"end_token_idx\"], samp.get(\"tar_number\", []))):\n",
    "        strict_total += 1\n",
    "        span_text = tokenizer.decode(token_ids[s:t])\n",
    "        span_text_m1 = tokenizer.decode(token_ids[s-1:t]).strip()\n",
    "        span_text_p1 = tokenizer.decode(token_ids[s+1:t]).strip()\n",
    "\n",
    "        is_match = False\n",
    "\n",
    "        if (span_text == num):\n",
    "            strict_ok += 1\n",
    "            is_match = True\n",
    "        # Check for a match with a left-shifted start index\n",
    "        elif (span_text_m1 == num):\n",
    "            strict_ok += 1\n",
    "            is_match = True\n",
    "            # Correct the start index in the sample\n",
    "            samp[\"start_token_idx\"][j] -= 1\n",
    "        # Check for a match with a right-shifted start index\n",
    "        elif (span_text_p1 == num):\n",
    "            strict_ok += 1\n",
    "            is_match = True\n",
    "            # Correct the start index in the sample\n",
    "            samp[\"start_token_idx\"][j] += 1\n",
    "        \n",
    "        # Append the match status (True or False) for the current tool call\n",
    "        samp[\"strict_match\"].append(is_match)\n",
    "\n",
    "        if not is_match:\n",
    "            mismatches_after_correction.append({\n",
    "                \"sample_idx\": i,\n",
    "                \"tool_call_idx\": j,\n",
    "                \"s\": s,\n",
    "                \"t\": t,\n",
    "                \"expected\": num,\n",
    "                \"span_text\": span_text,\n",
    "                \"ctx_left\": tokenizer.decode(token_ids[max(0, s-5):s]),\n",
    "                \"ctx_right\": tokenizer.decode(token_ids[t:min(len(token_ids), t+5)]),\n",
    "            })\n",
    "\n",
    "print(f\"Strict — total: {strict_total}, matches (with correction): {strict_ok}, mismatches: {len(mismatches_after_correction)}\")\n",
    "\n",
    "# Show a few remaining mismatches for inspection\n",
    "for r in mismatches_after_correction[:10]:\n",
    "    print(\"-\"*50)\n",
    "    print({k: r[k] for k in [\"sample_idx\", \"tool_call_idx\", \"s\", \"t\", \"expected\", \"span_text\"]})\n",
    "    print(\"L:\", r[\"ctx_left\"])\n",
    "    print(\"R:\", r[\"ctx_right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c0c738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Natalia sold 48/2 = 24 clips in May.\\nNatalia sold 48+24 = 72 clips altogether in April and May.\\n#### 72',\n",
       " 'start_token_idx': [11, 29],\n",
       " 'end_token_idx': [13, 31],\n",
       " 'tar_eq': ['<divide>(48, 2)=24', '<add>(48, 24)=72'],\n",
       " 'tar_number': ['24', '72'],\n",
       " 'strict_match': [True, True]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05c956b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed data saved to outputs\\gsm8k_gemma-4b-pt.json\n",
      "✅ Function dictionary saved to outputs\\func_dict.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# --- Save the processed data ---\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(\"outputs\", \"gsm8k_gemma-4b-pt.json\")\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(processed_samples, f, indent=4)\n",
    "print(f\"✅ Processed data saved to {output_path}\")\n",
    "\n",
    "# --- Create and save the final function dictionary ---\n",
    "func_dict = {\n",
    "    \"<add>\": 0,\n",
    "    \"<subtract>\": 1,\n",
    "    \"<multiply>\": 2,\n",
    "    \"<divide>\": 3\n",
    "}\n",
    "func_dict_path = os.path.join(\"outputs\", \"func_dict.json\")\n",
    "with open(func_dict_path, 'w') as f:\n",
    "    json.dump(func_dict, f, indent=4)\n",
    "print(f\"✅ Function dictionary saved to {func_dict_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d4034bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total original samples: 6054\n",
      "Matching samples found: 5799 (95.79%)\n",
      "Text matches: 5799 (95.79%)\n",
      "Target equation matches: 5564 (91.91%)\n",
      "Target number matches: 5760 (95.14%)\n",
      "\n",
      "Mismatches saved to outputs/mismatches.json\n",
      "\n",
      "Mismatches saved to outputs/mismatches.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "original_path = \"data/gsm8k-xl/train.json\"\n",
    "processed_path = \"outputs/gsm8k_gemma-4b-pt.json\"\n",
    "\n",
    "with open(original_path, 'r') as f:\n",
    "    original = json.load(f)\n",
    "\n",
    "with open(processed_path, 'r') as f:\n",
    "    processed = json.load(f)\n",
    "\n",
    "# Statistics\n",
    "total_samples = len(original)\n",
    "found_matches = 0\n",
    "text_matches = 0\n",
    "tar_eq_matches = 0\n",
    "tar_number_matches = 0\n",
    "\n",
    "# Store mismatches\n",
    "mismatches = {\n",
    "    'text_mismatches': [],\n",
    "    'tar_eq_mismatches': [],\n",
    "    'tar_number_mismatches': []\n",
    "}\n",
    "\n",
    "# Create a dictionary of processed samples with text as key for faster lookup\n",
    "processed_dict = {p['text']: p for p in processed}\n",
    "\n",
    "for i, o_sample in enumerate(original):\n",
    "    # Try to find matching text in processed samples\n",
    "    if o_sample['text'] in processed_dict:\n",
    "        found_matches += 1\n",
    "        p_sample = processed_dict[o_sample['text']]\n",
    "        \n",
    "        # Compare each field\n",
    "        if o_sample['text'] == p_sample['text']:\n",
    "            text_matches += 1\n",
    "        else:\n",
    "            mismatches['text_mismatches'].append({\n",
    "                'index': i,\n",
    "                'original': o_sample['text'],\n",
    "                'processed': p_sample['text']\n",
    "            })\n",
    "\n",
    "        c = [item.replace(\"<eoe>\", \"\") for item in o_sample['tar_eq']]\n",
    "        if c == p_sample['tar_eq']:\n",
    "            tar_eq_matches += 1\n",
    "        else:\n",
    "            mismatches['tar_eq_mismatches'].append({\n",
    "                'index': i,\n",
    "                'original': o_sample['tar_eq'],\n",
    "                'processed': p_sample['tar_eq']\n",
    "            })\n",
    "        \n",
    "        n = [item.replace(\",\", \"\") for item in p_sample['tar_number']]\n",
    "        if o_sample['tar_number'] == n:\n",
    "            tar_number_matches += 1\n",
    "        else:\n",
    "            mismatches['tar_number_mismatches'].append({\n",
    "                'index': i,\n",
    "                'original': o_sample['tar_number'],\n",
    "                'processed': p_sample['tar_number']\n",
    "            })\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Total original samples: {total_samples}\")\n",
    "print(f\"Matching samples found: {found_matches} ({found_matches/total_samples:.2%})\")\n",
    "print(f\"Text matches: {text_matches} ({text_matches/total_samples:.2%})\")\n",
    "print(f\"Target equation matches: {tar_eq_matches} ({tar_eq_matches/total_samples:.2%})\")\n",
    "print(f\"Target number matches: {tar_number_matches} ({tar_number_matches/total_samples:.2%})\")\n",
    "\n",
    "# Save mismatches to file\n",
    "mismatch_path = \"outputs/mismatches.json\"\n",
    "with open(mismatch_path, 'w') as f:\n",
    "    json.dump(mismatches, f, indent=4)\n",
    "print(f\"\\nMismatches saved to {mismatch_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52acca84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad85cf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 7473\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "850c84fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7473"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d8e87d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Original and processed datasets have different lengths",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(original) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(processed_samples), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal and processed datasets have different lengths\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Original and processed datasets have different lengths"
     ]
    }
   ],
   "source": [
    "assert len(original) == len(processed_samples), \"Original and processed datasets have different lengths\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdb480ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text mismatches found: 0.00%\n"
     ]
    }
   ],
   "source": [
    "text_mismatch = 0\n",
    "for o_sample, gsm, p_sample in zip(original, processed_samples, ds['train']):\n",
    "    full_text = p_sample['question'] + \" Let's think step by step. \" + gsm['text']\n",
    "\n",
    "    try:\n",
    "        assert \"Let's think step by step.\" in o_sample['text'], \"Missing 'Let's think step by step.' in original text\"\n",
    "        #assert o_sample['text'] == full_text, \"Text mismatch\"\n",
    "    except:\n",
    "        print(f\"Original: {o_sample['text']}\")\n",
    "        print(f\"Processed: {full_text}\")\n",
    "        text_mismatch += 1\n",
    "        continue\n",
    "    #assert o_sample['start_token_idx'] == p_sample['start_token_idx'], \"Start indices mismatch\"\n",
    "    #assert o_sample['end_token_idx'] == p_sample['end_token_idx'], \"End indices mismatch\"\n",
    "    #assert o_sample['tar_eq'] == p_sample['tar_eq'], \"Target equations mismatch\"\n",
    "    #assert o_sample['tar_number'] == p_sample['tar_number'], \"Target numbers mismatch\"\n",
    "\n",
    "print(f\"Text mismatches found: {text_mismatch/len(original):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27568b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
