{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dacab2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf1a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"svamp\"\n",
    "llm = \"gemma-3-4b-pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e8de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(f\"openai/{dataset}\", \"main\")\n",
    "\n",
    "print(ds)\n",
    "\n",
    "example = ds[\"train\"][0]\n",
    "print(\"Example:\", example)\n",
    "\n",
    "print(\"\\n\\nQuestion:\", example[\"question\"], \"\\n\\n\")\n",
    "print(\"Answer:\", example[\"answer\"])''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff99c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9e649d17ff4761ab2d2000135ec644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa51671764f455c82ce1b6b7ebf28ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 800\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n",
      "{'question': \"In Haley's class 13 boys love to play marbles and 50 boys love to play cards. If Haley has 26 marbles How many will each of the boys receive?\", 'answer': 'The final answer is (26/13) = <<(26/13)=2>>2'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import re\n",
    "\n",
    "# 1) Load dataset\n",
    "raw = load_dataset(f\"garrethlee/{dataset}\")  # has 'train' and 'test' splits\n",
    "\n",
    "# 2) Parser: from \"( 26 / 13 ) = 2 #### 2\" -> eq=\"26/13\", ans=\"2\"\n",
    "eq_ans_re = re.compile(\n",
    "    r\"\"\"            # whole answer field\n",
    "    (?P<lhs>.+?)    # left side including equation text\n",
    "    \\s*####\\s*\n",
    "    (?P<ans>[-+]?\\d+(?:\\.\\d+)?)\\s*$   # numeric final answer\n",
    "    \"\"\",\n",
    "    re.VERBOSE,\n",
    ")\n",
    "\n",
    "def normalize_equation(lhs: str) -> str:\n",
    "    \"\"\"\n",
    "    lhs examples:\n",
    "      \"( 26 / 13 ) = 2\"\n",
    "      \"( ( 11 - 2 ) - 2 ) = 7\"\n",
    "    We take the text before '=', strip spaces, but preserve parentheses.\n",
    "    \"\"\"\n",
    "    # take everything before '='\n",
    "    before_eq = lhs.split('=')[0].strip()\n",
    "    # remove all spaces\n",
    "    before_eq = before_eq.replace(' ', '')\n",
    "    # also collapse redundant outer parentheses like \"((a))\" -> \"(a)\" (optional)\n",
    "    # simple pass: keep as-is; downstream doesn't require removal\n",
    "    return before_eq\n",
    "\n",
    "def to_gsm8k_style(example):\n",
    "    \"\"\"\n",
    "    Produce:\n",
    "      question: copy as-is\n",
    "      answer: \"<eq> = <<eq=ans>>ans\"\n",
    "    \"\"\"\n",
    "    text = example[\"answer\"]\n",
    "    m = eq_ans_re.match(text)\n",
    "    if not m:\n",
    "        # fallback: if the format deviates, return minimal passthrough\n",
    "        eq = \"\"\n",
    "        ans = \"\"\n",
    "    else:\n",
    "        lhs = m.group(\"lhs\")\n",
    "        ans = m.group(\"ans\")\n",
    "        eq = normalize_equation(lhs)\n",
    "\n",
    "    return {\n",
    "        \"question\": example[\"question\"],\n",
    "        \"answer\": f\"The final answer is {eq} = <<{eq}={ans}>>{ans}\",\n",
    "    }\n",
    "\n",
    "# 3) Transform both splits, keep only the 2 fields\n",
    "processed = {}\n",
    "for split in raw.keys():  # 'train', 'test'\n",
    "    processed[split] = raw[split].map(\n",
    "        to_gsm8k_style,\n",
    "        remove_columns=raw[split].column_names\n",
    "    )\n",
    "\n",
    "# 4) Ensure final variable name is `ds` and contains only 'train' and 'test'\n",
    "ds = DatasetDict(processed)\n",
    "\n",
    "# 5) Quick inspection\n",
    "print(ds)\n",
    "print(ds[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc466f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"google/{llm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbea7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tool_call_pattern = re.compile(r'(<<[^>]+>>)([^<]*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a1bfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(30, 44), match='<<(26/13)=2>>2'>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tool_call_pattern.finditer(ds['train'][0]['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e88ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tool_call(expression: str):\n",
    "    \"\"\"\n",
    "    Parses a mathematical expression and converts it into the ToolkenGPT format.\n",
    "    Examples: \n",
    "    \"48/2=24\" -> \"<divide>(48, 2)=24\"\n",
    "    \"+30+46+38+11+18=143\" -> \"<add>(30, 46, 38, 11, 18)=143\"\n",
    "    \"\"\"\n",
    "    # Simple mapping from operator to function name\n",
    "    op_to_func = {\n",
    "        '+': 'add',\n",
    "        '-': 'subtract',\n",
    "        '*': 'multiply',\n",
    "        '/': 'divide'\n",
    "    }\n",
    "\n",
    "    # Find the operator and split on equals sign\n",
    "    if '=' in expression:\n",
    "        expr_part, result = expression.split('=', 1)\n",
    "        result = result.strip()\n",
    "        \n",
    "        # Handle multiple additions/subtractions\n",
    "        for op, func_name in op_to_func.items():\n",
    "            if op in expr_part:\n",
    "                # Skip if it's just a leading sign\n",
    "                if expr_part.strip() == op:\n",
    "                    continue\n",
    "                    \n",
    "                # Split on operator, filter out empty strings\n",
    "                parts = [p.strip() for p in expr_part.split(op) if p.strip()]\n",
    "                \n",
    "                # If we found valid parts, convert to function call format\n",
    "                if parts:\n",
    "                    return f\"<{func_name}>({', '.join(parts)})={result}\"\n",
    "    \n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a6ba32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<add>(30, 46, 18)=100'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_tool_call(\"30+46+18=100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "111d3791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The final answer is (11+8) = <<(11+8)=19>>19'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][108]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9bafc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index by searching through processed samples\n",
    "'''found_idx = next((i for i, sample in enumerate(processed_samples) \n",
    "                  if sample['text'] == original[108]['text']), None)\n",
    "print(found_idx)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec2436c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The final answer is (6-(2+3)) = <<(6-(2+3))=1>>1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][140][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0523de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original[108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0586b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 2944.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch ratio: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "verbose = 1\n",
    "mismatches = 0\n",
    "\n",
    "\n",
    "processed_samples = []\n",
    "\n",
    "\n",
    "for sample in tqdm(ds['train']):\n",
    "    start_indices = []\n",
    "    end_indices = []\n",
    "    target_equations = []\n",
    "    target_numbers = []\n",
    "        \n",
    "    removed_chars_offset = 0\n",
    "\n",
    "    full_text = sample['question'] + \" Let's think step by step. \" + sample['answer']\n",
    "\n",
    "    matches = list(tool_call_pattern.finditer(full_text))\n",
    "\n",
    "    # Create the final clean text by removing only the <<...>> syntax.\n",
    "    clean_text = re.sub(r'<<[^>]+>>', '', full_text)\n",
    "\n",
    "    start_indices = []\n",
    "    end_indices = []\n",
    "    target_equations = []\n",
    "    target_numbers = []\n",
    "\n",
    "    removed_chars_offset = 0\n",
    "\n",
    "    for match in matches:\n",
    "        expression_part = match.group(1) # The <<...>> part\n",
    "    \n",
    "        expression = expression_part[2:-2] # The content inside\n",
    "        expression = re.sub(r'(?<=[\\s=+\\-*/])\\.(\\d+)', r'0.\\1', expression)  # Add 0 before decimal points\n",
    "\n",
    "        following_text = match.group(2) # The text after <<...>>\n",
    "        \n",
    "        # The pattern should handle negative numbers as well.\n",
    "        number_pattern = re.compile(r'-?[\\d,]*\\.?\\d+')\n",
    "        num_match = number_pattern.search(following_text)\n",
    "        num = num_match.group(0) if num_match else None\n",
    "        expected_num_str = expression.split('=')[-1].strip()\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            assert num == expected_num_str\n",
    "        except AssertionError:\n",
    "            mismatches += 1\n",
    "            print(\"-\"*25)\n",
    "            print(num_match)\n",
    "            print(f\"Full text: {sample['answer']}\")\n",
    "            print(\"/\"*10)\n",
    "            print(f\"Found match: {match.group(0)}\")\n",
    "            print(f\"Expression part: {expression_part}\")\n",
    "            print(f\"Following text: {following_text}\")\n",
    "            print(f\"Number found: {num}\")\n",
    "            print(f\"Expected number from expression: {expected_num_str}\")\n",
    "        \"\"\"\n",
    "        # 1. Calculate the character position of where the number *starts* in the clean_text.\n",
    "        char_pos_start = (match.start() - removed_chars_offset) + num_match.start()\n",
    "\n",
    "        # 2. Tokenize the clean text *before* the number's position to find the start_idx.\n",
    "        text_before_result = clean_text[:char_pos_start]\n",
    "        tokens_before = tokenizer.encode(text_before_result)\n",
    "        start_idx = len(tokens_before)\n",
    "\n",
    "        # 3. Calculate the character position of where the number *ends* in the clean_text.\n",
    "        char_pos_end = char_pos_start + len(num)\n",
    "        \n",
    "        # 4. Tokenize the clean text up to the *end* of the number. The length of this\n",
    "        #    token sequence is our end_idx.\n",
    "        text_up_to_end_of_result = clean_text[:char_pos_end]\n",
    "        tokens_up_to_end = tokenizer.encode(text_up_to_end_of_result)\n",
    "        end_idx = len(tokens_up_to_end)\n",
    "\n",
    "        # 5. Store the start and end indices for the current match.\n",
    "        start_indices.append(start_idx)\n",
    "        end_indices.append(end_idx)\n",
    "        target_equations.append(parse_tool_call(expression))\n",
    "\n",
    "        target_numbers.append(num)\n",
    "\n",
    "        # Update the offset for the next iteration by adding the length of the\n",
    "        # <<...>> syntax string we just processed.\n",
    "        removed_chars_offset += len(expression_part)\n",
    "\n",
    "        if num != expected_num_str and False:\n",
    "            print(f\"Text: {clean_text}\")\n",
    "            print(f\"Before: {text_before_result}\")\n",
    "            print(f\"After: {text_up_to_end_of_result}\")\n",
    "            print(f\"Target equations: {target_equations}\")\n",
    "    \n",
    "    processed_samples.append({\n",
    "            \"text\": clean_text,\n",
    "            \"start_token_idx\": start_indices,\n",
    "            \"end_token_idx\": end_indices,\n",
    "            \"tar_eq\": target_equations,\n",
    "            \"tar_number\": target_numbers,\n",
    "        })\n",
    "\n",
    "print(f\"Mismatch ratio: {mismatches/len(ds['train'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b5771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<(16+6)=22>>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expression_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5a8c28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(16+6)=22'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f41502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "following_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24f66b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(mismatches_after_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dff6cbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict — total: 800, matches (with correction): 800, mismatches: 0\n"
     ]
    }
   ],
   "source": [
    "# Strict validation: update samples in-place with corrected indices and match status.\n",
    "strict_total = 0\n",
    "strict_ok = 0\n",
    "mismatches_after_correction = []\n",
    "\n",
    "for i, samp in enumerate(processed_samples):\n",
    "    # Initialize a new list to store the match status for each tool call in the sample\n",
    "    samp[\"strict_match\"] = []\n",
    "    \n",
    "    # keep tokenizer behavior consistent with above preprocessing (same encode)\n",
    "    token_ids = tokenizer.encode(samp[\"text\"])\n",
    "    \n",
    "    # Enumerate to get the index 'j' for updating the lists\n",
    "    for j, (s, t, num) in enumerate(zip(samp[\"start_token_idx\"], samp[\"end_token_idx\"], samp.get(\"tar_number\", []))):\n",
    "        strict_total += 1\n",
    "        span_text = tokenizer.decode(token_ids[s:t])\n",
    "        span_text_m1 = tokenizer.decode(token_ids[s-1:t]).strip()\n",
    "        span_text_p1 = tokenizer.decode(token_ids[s+1:t]).strip()\n",
    "\n",
    "        is_match = False\n",
    "\n",
    "        if (span_text == num):\n",
    "            strict_ok += 1\n",
    "            is_match = True\n",
    "        # Check for a match with a left-shifted start index\n",
    "        elif (span_text_m1 == num):\n",
    "            strict_ok += 1\n",
    "            is_match = True\n",
    "            # Correct the start index in the sample\n",
    "            samp[\"start_token_idx\"][j] -= 1\n",
    "        # Check for a match with a right-shifted start index\n",
    "        elif (span_text_p1 == num):\n",
    "            strict_ok += 1\n",
    "            is_match = True\n",
    "            # Correct the start index in the sample\n",
    "            samp[\"start_token_idx\"][j] += 1\n",
    "        \n",
    "        # Append the match status (True or False) for the current tool call\n",
    "        samp[\"strict_match\"].append(is_match)\n",
    "\n",
    "        if not is_match:\n",
    "            mismatches_after_correction.append({\n",
    "                \"sample_idx\": i,\n",
    "                \"tool_call_idx\": j,\n",
    "                \"s\": s,\n",
    "                \"t\": t,\n",
    "                \"expected\": num,\n",
    "                \"span_text\": span_text,\n",
    "                \"ctx_left\": tokenizer.decode(token_ids[max(0, s-5):s]),\n",
    "                \"ctx_right\": tokenizer.decode(token_ids[t:min(len(token_ids), t+5)]),\n",
    "            })\n",
    "\n",
    "print(f\"Strict — total: {strict_total}, matches (with correction): {strict_ok}, mismatches: {len(mismatches_after_correction)}\")\n",
    "\n",
    "# Show a few remaining mismatches for inspection\n",
    "for r in mismatches_after_correction[:10]:\n",
    "    print(\"-\"*50)\n",
    "    print({k: r[k] for k in [\"sample_idx\", \"tool_call_idx\", \"s\", \"t\", \"expected\", \"span_text\"]})\n",
    "    print(\"L:\", r[\"ctx_left\"])\n",
    "    print(\"R:\", r[\"ctx_right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8c0c738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"In Haley's class 13 boys love to play marbles and 50 boys love to play cards. If Haley has 26 marbles How many will each of the boys receive? Let's think step by step. The final answer is (26/13) = 2\",\n",
       " 'start_token_idx': [61],\n",
       " 'end_token_idx': [62],\n",
       " 'tar_eq': ['<divide>((26, 13))=2'],\n",
       " 'tar_number': ['2'],\n",
       " 'strict_match': [True]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05c956b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed data saved to outputs/svamp_gemma-3-4b-pt.json\n",
      "✅ Function dictionary saved to outputs/func_dict.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# --- Save the processed data ---\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(\"outputs\", f\"{dataset}_{llm}.json\")\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(processed_samples, f, indent=4)\n",
    "print(f\"✅ Processed data saved to {output_path}\")\n",
    "\n",
    "# --- Create and save the final function dictionary ---\n",
    "func_dict = {\n",
    "    \"<add>\": 0,\n",
    "    \"<subtract>\": 1,\n",
    "    \"<multiply>\": 2,\n",
    "    \"<divide>\": 3\n",
    "}\n",
    "func_dict_path = os.path.join(\"outputs\", \"func_dict.json\")\n",
    "with open(func_dict_path, 'w') as f:\n",
    "    json.dump(func_dict, f, indent=4)\n",
    "print(f\"✅ Function dictionary saved to {func_dict_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d4034bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import json\n",
    "\n",
    "original_path = os.path.join(\"outputs\", f\"{dataset}_{llm}_original.json\")\n",
    "processed_path = os.path.join(\"outputs\", f\"{dataset}_{llm}.json\")\n",
    "\n",
    "with open(original_path, 'r') as f:\n",
    "    original = json.load(f)\n",
    "\n",
    "with open(processed_path, 'r') as f:\n",
    "    processed = json.load(f)\n",
    "\n",
    "# Statistics\n",
    "total_samples = len(original)\n",
    "found_matches = 0\n",
    "text_matches = 0\n",
    "tar_eq_matches = 0\n",
    "tar_number_matches = 0\n",
    "\n",
    "# Store mismatches\n",
    "mismatches = {\n",
    "    'text_mismatches': [],\n",
    "    'tar_eq_mismatches': [],\n",
    "    'tar_number_mismatches': []\n",
    "}\n",
    "\n",
    "# Create a dictionary of processed samples with text as key for faster lookup\n",
    "processed_dict = {p['text']: p for p in processed}\n",
    "\n",
    "for i, o_sample in enumerate(original):\n",
    "    # Try to find matching text in processed samples\n",
    "    if o_sample['text'] in processed_dict:\n",
    "        found_matches += 1\n",
    "        p_sample = processed_dict[o_sample['text']]\n",
    "        \n",
    "        # Compare each field\n",
    "        if o_sample['text'] == p_sample['text']:\n",
    "            text_matches += 1\n",
    "        else:\n",
    "            mismatches['text_mismatches'].append({\n",
    "                'index': i,\n",
    "                'original': o_sample['text'],\n",
    "                'processed': p_sample['text']\n",
    "            })\n",
    "\n",
    "        c = [item.replace(\"<eoe>\", \"\") for item in o_sample['tar_eq']]\n",
    "        if c == p_sample['tar_eq']:\n",
    "            tar_eq_matches += 1\n",
    "        else:\n",
    "            mismatches['tar_eq_mismatches'].append({\n",
    "                'index': i,\n",
    "                'original': o_sample['tar_eq'],\n",
    "                'processed': p_sample['tar_eq']\n",
    "            })\n",
    "        \n",
    "        n = [item.replace(\",\", \"\") for item in p_sample['tar_number']]\n",
    "        if o_sample['tar_number'] == n:\n",
    "            tar_number_matches += 1\n",
    "        else:\n",
    "            mismatches['tar_number_mismatches'].append({\n",
    "                'index': i,\n",
    "                'original': o_sample['tar_number'],\n",
    "                'processed': p_sample['tar_number']\n",
    "            })\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Total original samples: {total_samples}\")\n",
    "print(f\"Matching samples found: {found_matches} ({found_matches/total_samples:.2%})\")\n",
    "print(f\"Text matches: {text_matches} ({text_matches/total_samples:.2%})\")\n",
    "print(f\"Target equation matches: {tar_eq_matches} ({tar_eq_matches/total_samples:.2%})\")\n",
    "print(f\"Target number matches: {tar_number_matches} ({tar_number_matches/total_samples:.2%})\")\n",
    "\n",
    "# Save mismatches to file\n",
    "mismatch_path = \"outputs/mismatches.json\"\n",
    "with open(mismatch_path, 'w') as f:\n",
    "    json.dump(mismatches, f, indent=4)\n",
    "print(f\"\\nMismatches saved to {mismatch_path}\")''';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52acca84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"In Haley's class 13 boys love to play marbles and 50 boys love to play cards. If Haley has 26 marbles How many will each of the boys receive?\",\n",
       " 'answer': 'The final answer is (26/13) = <<(26/13)=2>>2'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad85cf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 800\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "850c84fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d8e87d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert len(original) == len(processed_samples), \"Original and processed datasets have different lengths\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdb480ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''text_mismatch = 0\n",
    "for o_sample, gsm, p_sample in zip(original, processed_samples, ds['train']):\n",
    "    full_text = p_sample['question'] + \" Let's think step by step. \" + gsm['text']\n",
    "\n",
    "    try:\n",
    "        assert \"Let's think step by step.\" in o_sample['text'], \"Missing 'Let's think step by step.' in original text\"\n",
    "        #assert o_sample['text'] == full_text, \"Text mismatch\"\n",
    "    except:\n",
    "        print(f\"Original: {o_sample['text']}\")\n",
    "        print(f\"Processed: {full_text}\")\n",
    "        text_mismatch += 1\n",
    "        continue\n",
    "    #assert o_sample['start_token_idx'] == p_sample['start_token_idx'], \"Start indices mismatch\"\n",
    "    #assert o_sample['end_token_idx'] == p_sample['end_token_idx'], \"End indices mismatch\"\n",
    "    #assert o_sample['tar_eq'] == p_sample['tar_eq'], \"Target equations mismatch\"\n",
    "    #assert o_sample['tar_number'] == p_sample['tar_number'], \"Target numbers mismatch\"\n",
    "\n",
    "print(f\"Text mismatches found: {text_mismatch/len(original):.2%}\")''';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rmt_env_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
